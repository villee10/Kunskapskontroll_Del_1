{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ville/repos/Ai-teori och tillämpning, del2/.venv/lib/python3.13/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import keras_tuner as kt\n",
    "\n",
    "\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "(10000,)\n",
      "true lable for the plotted images is: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1, cache=True, as_frame=False)\n",
    "X = mnist[\"data\"][:10000]\n",
    "Y = mnist[\"target\"][:10000].astype(np.uint8)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "\n",
    "some_digit = X[0]\n",
    "some_digit_image = some_digit.reshape(28, 28)\n",
    "plt.imshow(some_digit_image, cmap = mpl.cm.binary)\n",
    "print(\"true lable for the plotted images is:\", Y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tenserflow och keras\n",
    "# Load the data (MNIST is built into Keras, which is faster than fetch_openml)\n",
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize pixels (from 0-255 to 0-1) - ANNs love small values!\n",
    "X_train_full, X_test = X_train_full / 255.0, X_test / 255.0\n",
    "\n",
    "# Extracting 5000 images from the training set to be used as a validation set.\n",
    "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
    "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ville/repos/Ai-teori och tillämpning, del2/.venv/lib/python3.13/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Step 2: build the ANN \n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]), # Remake the 28x28 pictures into a long string of 784 pixels\n",
    "    keras.layers.Dense(300, activation=\"relu\"), \n",
    "    keras.layers.Dense(100, activation=\"relu\"), \n",
    "    keras.layers.Dense(10, activation=\"softmax\") \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1375/1375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0128 - val_accuracy: 0.9965 - val_loss: 0.0120\n",
      "Epoch 2/10\n",
      "\u001b[1m1375/1375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0092 - val_accuracy: 0.9962 - val_loss: 0.0159\n",
      "Epoch 3/10\n",
      "\u001b[1m1375/1375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0046 - val_accuracy: 0.9970 - val_loss: 0.0118\n",
      "Epoch 4/10\n",
      "\u001b[1m1375/1375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9980 - loss: 0.0073 - val_accuracy: 0.9898 - val_loss: 0.0474\n",
      "Epoch 5/10\n",
      "\u001b[1m1375/1375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9969 - loss: 0.0115 - val_accuracy: 0.9905 - val_loss: 0.0376\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#step 3: compile and train the model \n",
    "model.compile(optimizer=\"adam\", \n",
    "              loss=\"sparse_categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience = 2)\n",
    "trained_model_2 = model.fit(X_train, y_train, epochs=10, callbacks = [early_stopping_monitor])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KerasTuner model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "    \n",
    "    # Tuner testing the Number of Neuron. between 32 and 512\n",
    "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "    model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "    \n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    # Tuner Learning Rate Selection\n",
    "    hp_lr = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_lr),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir/mnist_tuning/tuner0.json\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 123ms/step - accuracy: 0.9688 - loss: 0.0495"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ville/repos/Ai-teori och tillämpning, del2/.venv/lib/python3.13/site-packages/keras/src/saving/saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 10 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - accuracy: 0.9749 - loss: 0.0802\n",
      "Test precision för den optimerade modellen: 0.9749000072479248\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    directory='my_dir',\n",
    "    project_name='mnist_tuning'\n",
    ")\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "# Start\n",
    "tuner.search(X_train, y_train, \n",
    "             epochs=10, \n",
    "             validation_data=(X_valid, y_valid),\n",
    "             callbacks=[early_stopping_monitor])\n",
    "\n",
    "# Retrieve the Best Model and Evaluate\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
    "print(f\"Test precision för den optimerade modellen: {test_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
